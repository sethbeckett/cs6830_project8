{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS6830 Project 8\n",
    "Seth Beckett and Jasper Swenson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import random\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from IPython.display import SVG\n",
    "# You may need to install the Python graphviz library. At the command line:\n",
    "#   pip install graphviz\n",
    "# You will also need to install the graphviz executables. You can use apt,\n",
    "# macports, or other installer for your system.\n",
    "from graphviz import Source\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('glass.csv')\n",
    "model_precision = {\"Max Depth 3\": 0, \"Max Depth 5\": 0}\n",
    "model_recall = {\"Max Depth 3\": 0, \"Max Depth 5\": 0}\n",
    "model_fscore = {\"Max Depth 3\": 0, \"Max Depth 5\": 0}\n",
    "display(df)\n",
    "\n",
    "feature_cols = [\"RI\", \"Na\", \"Mg\", \"Al\", \"Si\", \"K\", \"Ca\", \"Ba\", \"Fe\"]\n",
    "df_x = df[feature_cols]\n",
    "df_y = df[[\"Type\"]]\n",
    "# display(df_x)\n",
    "# display(df_y)\n",
    "\n",
    "x = df_x.values\n",
    "y = df_y.values\n",
    "print(x[0])\n",
    "print(y[0])\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.25)\n",
    "print(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeclf1 = DecisionTreeClassifier(max_depth=3, random_state=1)\n",
    "treeclf1.fit(xtrain, ytrain)\n",
    "y_pred = treeclf1.predict(xtest)\n",
    "p,r,f,s = precision_recall_fscore_support(ytest, y_pred)\n",
    "model_fscore[\"Max Depth 3\"] = [(f[0]+f[1] / 2)]\n",
    "model_recall[\"Max Depth 3\"] = [(r[0]+r[1] / 2)]\n",
    "model_precision[\"Max Depth 3\"] = [(p[0]+p[1] / 2)]\n",
    "display('Depth 3 precision = {}'.format(p))\n",
    "display('Depth 3 recall = {}'.format(r))\n",
    "display('Depth 3 f-score = {}'.format(f))\n",
    "\n",
    "treeclf2 = DecisionTreeClassifier(max_depth=5, random_state=1)\n",
    "treeclf2.fit(xtrain, ytrain)\n",
    "y_pred = treeclf2.predict(xtest)\n",
    "p,r,f,s = precision_recall_fscore_support(ytest, y_pred)\n",
    "model_fscore[\"Max Depth 5\"] = [(f[0]+f[1] / 2)]\n",
    "model_recall[\"Depth 5\"] = [(r[0]+r[1] / 2)]\n",
    "model_precision[\"Max Depth 5\"] = [(p[0]+p[1] / 2)]\n",
    "display('Depth 5 precision = {}'.format(p))\n",
    "display('Depth 5 recall = {}'.format(r))\n",
    "display('Max Depth 5 f-score = {}'.format(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph1 = Source(tree.export_graphviz(treeclf1, out_file=None,\n",
    "                                    feature_names=feature_cols,\n",
    "                                    class_names=['1', '2', '3', '4', '5', '6', '7'], filled = True))\n",
    "display(SVG(graph1.pipe(format='svg')))\n",
    "\n",
    "graph2 = Source(tree.export_graphviz(treeclf2, out_file=None,\n",
    "                                    feature_names=feature_cols,\n",
    "                                    class_names=['1', '2', '3', '4', '5', '6', '7'], filled = True))\n",
    "display(SVG(graph2.pipe(format='svg')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance1 = pd.DataFrame({'feature':feature_cols, 'importance':treeclf1.feature_importances_})\n",
    "display(importance1)\n",
    "importance1.plot(kind='barh', figsize=(9, 7))\n",
    "plt.title('Feature Significance For DecisionTreeClassifier With Max Depth 3')\n",
    "plt.axvline(x=0, color='.5')\n",
    "plt.subplots_adjust(left=.3)\n",
    "\n",
    "importance2 = pd.DataFrame({'feature':feature_cols, 'importance':treeclf2.feature_importances_})\n",
    "display(importance2)\n",
    "importance2.plot(kind='barh', figsize=(9, 7))\n",
    "plt.title('Feature Significance For DecisionTreeClassifier With Max Depth 5')\n",
    "plt.axvline(x=0, color='.5')\n",
    "plt.subplots_adjust(left=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_df = pd.DataFrame.from_dict(model_precision)\n",
    "display(precision_df)\n",
    "display(precision_df.plot.bar().set_title(\"DecisionTreeClassifier Model Precision Score\"))\n",
    "fscore_df = pd.DataFrame.from_dict(model_fscore)\n",
    "display(fscore_df)\n",
    "display(fscore_df.plot.bar().set_title(\"Model FScore\"))\n",
    "recall_df = pd.DataFrame.from_dict(model_recall)\n",
    "display(recall_df)\n",
    "display(recall_df.plot.bar().set_title(\"Model Recall Score\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get necessary libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate, cross_val_predict\n",
    "from sklearn.metrics import classification_report,confusion_matrix, ConfusionMatrixDisplay\n",
    "import networkx as nx\n",
    "import colorsys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x)\n",
    "x_scaled = scaler.transform(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use gridsearch to find best parameters for mlp classifier\n",
    "mlp = MLPClassifier(max_iter=5000)\n",
    "param_grid = {'hidden_layer_sizes': [(50, 10), (50, 25), (50, 50), (50, 100), (100, 10), (100, 25), (100, 50), (100, 100)],\n",
    "                'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "                'solver': ['sgd', 'adam', 'lbfgs']}\n",
    "grid = GridSearchCV(mlp, param_grid, n_jobs=-1)\n",
    "grid.fit(x_scaled, y.ravel())\n",
    "\n",
    "# print best parameters\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more paramsearch\n",
    "mlp = MLPClassifier(max_iter=1000)\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [\n",
    "        (10,), (20,), (30,), (40,), (50,),  # single hidden layer\n",
    "        (10, 10), (20, 20), (30, 30), (40, 40), (50, 50),  # two hidden layers\n",
    "        (10, 20), (20, 10), (20, 30), (30, 20), (30, 40), (40, 30),  # two hidden layers with different sizes\n",
    "        (10, 10, 10), (20, 20, 20), (30, 30, 30), (40, 40, 40), (50, 50, 50),  # three hidden layers\n",
    "        (10, 20, 30), (30, 20, 10), (10, 30, 50), (50, 30, 10)  # three hidden layers with different sizes\n",
    "    ],\n",
    "    'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(mlp, param_grid, n_jobs=-1)\n",
    "grid.fit(x_scaled, y.ravel())\n",
    "\n",
    "# print best parameters\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use best parameters to create mlp classifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10, 20), activation='tanh', solver='adam', max_iter=5000, alpha=0.05)\n",
    "mlp.fit(xtrain, ytrain.ravel())\n",
    "predictions = mlp.predict(xtest)\n",
    "\n",
    "# print classification report\n",
    "print(classification_report(ytest,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use cross_val_predict instead since we have a small dataset\n",
    "predictions = cross_val_predict(mlp, x_scaled, y.ravel(), cv=7)\n",
    "print(classification_report(y,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize nn\n",
    "def show_ann(mlp):\n",
    "    hidden_layers_n = len(mlp.coefs_)-1\n",
    "    layers_n = hidden_layers_n + 2\n",
    "    input_neurons_n = len(mlp.coefs_[0])\n",
    "    hidden_neurons_n = [len(mlp.coefs_[i+1]) for i in range(hidden_layers_n)]\n",
    "    output_neurons_n = len(mlp.coefs_[-1][0])\n",
    "\n",
    "    G = nx.DiGraph()\n",
    "    pos = {}\n",
    "\n",
    "    # Create the neurons of the input layer\n",
    "    for i in range(input_neurons_n):\n",
    "        pos['Layer0_{}'.format(i)] = (i,layers_n-1)\n",
    "\n",
    "    for j in range(hidden_layers_n):\n",
    "        # Create the neurons of the j'th hidden layer\n",
    "        prev_layer = j\n",
    "        cur_layer = j+1\n",
    "        if (j == 0):\n",
    "            prev_size = input_neurons_n\n",
    "        else:\n",
    "            prev_size = hidden_neurons_n[j-1]\n",
    "        for i in range(hidden_neurons_n[j]):\n",
    "            pos['Layer{}_{}'.format(cur_layer,i)] = (i,layers_n-1-cur_layer)\n",
    "            for k in range(prev_size):\n",
    "                w = mlp.coefs_[prev_layer][k][i]\n",
    "                G.add_edge('Layer{}_{}'.format(prev_layer,k),'Layer{}_{}'.format(cur_layer,i), weight=w)\n",
    "\n",
    "    # Create the neurons of the output layer\n",
    "    prev_layer = hidden_layers_n\n",
    "    cur_layer = hidden_layers_n+1\n",
    "    for i in range(output_neurons_n):\n",
    "        pos['Layer{}_{}'.format(cur_layer,i)] = (i,layers_n-1-cur_layer)\n",
    "        for k in range(hidden_neurons_n[-1]):\n",
    "            w = mlp.coefs_[prev_layer][k][i]\n",
    "            G.add_edge('Layer{}_{}'.format(prev_layer,k),'Layer{}_{}'.format(cur_layer,i), weight=w)\n",
    "\n",
    "    edges = G.edges()\n",
    "    colors = [colorsys.hsv_to_rgb(0 if G[u][v]['weight'] < 0 else 0.65,\n",
    "                                  1,#min(1, abs(G[u][v]['weight'])),\n",
    "                                  1) for u,v in edges]\n",
    "    weights = [abs(G[u][v]['weight'])*2 for u,v in edges]\n",
    "\n",
    "    nx.draw(G, pos, node_color='y', node_size=450, width=weights, edge_color=colors)\n",
    "    \n",
    "show_ann(mlp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
